{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOPVcCE5LLFxH29EkFfmPrX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheDarkNight21/routellm-assignment/blob/main/cgan_implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorboardX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "fKvy7968mGkd",
        "outputId": "cecd0e99-c08b-4268-9771-415582fdac01"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.12/dist-packages (2.6.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from tensorboardX) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorboardX) (25.0)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.12/dist-packages (from tensorboardX) (5.29.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "pSZPu6KEE615"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.datasets import ImageFolder, CIFAR10\n",
        "from torchvision import transforms\n",
        "from torch import autograd\n",
        "from torch.autograd import Variable\n",
        "from torchvision.utils import make_grid\n",
        "from tensorboardX import SummaryWriter\n",
        "import torch.nn.utils.spectral_norm as spectral_norm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "print('torch version:',torch.__version__)\n",
        "print('device:', device)"
      ],
      "metadata": {
        "id": "iFnTcJ_nE_Dp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "292d2a8d-4e30-45df-92b0-70e4c9eb266f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch version: 2.8.0+cu126\n",
            "device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "pipeline of pre processing steps applied to each image"
      ],
      "metadata": {
        "id": "6UAh0ZKSpHba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(), # converts a PIL image/numpy array to torch.FloatTensor with shape (Channel, Height, Width)\n",
        "    transforms.Normalize([0.5], [0.5], [0.5]) # applies per channel normaliztion so values range from [-1, 1] instead of [0,1] -- good since we will be using tanh as final activation function\n",
        "    # need [0.5] 3 times since we have 3 channels (dataset is in RGB)\n",
        "    ])"
      ],
      "metadata": {
        "id": "_1wV3C8MpRNh"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "load data / parameters"
      ],
      "metadata": {
        "id": "Kc2Mo5Y8rYMn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_size = 32 # Image size\n",
        "batch_size = 64  # Batch size\n",
        "\n",
        "data_loader = torch.utils.data.DataLoader(CIFAR10('data', train=True, download=True, transform=transform), batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "nSQqfCYurBWw"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "projection discriminator\n",
        "\n",
        "this is how it will look like:\n",
        "\n",
        "$D(x, y) = h (f(x)) + <f(x), e(y)>$\n",
        "where, $h (f(x))$ determines how real the image looks and\n",
        "$<f(x), e(y)>$ determines if the features match the label assigned to the image"
      ],
      "metadata": {
        "id": "IKu4iM9osgqF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# nn.Module makes our lives easier; it is a base class that tracks all parameters and needs a forward() method for forward prop\n",
        "class conditionalDiscriminator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    # self.___ are all called modules\n",
        "\n",
        "    self.model = nn.Sequential(\n",
        "        spectral_norm(nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=2, padding=1)), # shape: [N, 64, 16, 16]; N is batch size\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "        spectral_norm(nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=2, padding=1)), # shape: [N, 128, 8, 8]; N is batch size\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "        spectral_norm(nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=2, padding=1)), # shape: [N, 256, 4, 4]; N is batch size\n",
        "        nn.LeakyReLU(0.2, inplace=True)\n",
        "    )\n",
        "\n",
        "    self.pooling = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
        "\n",
        "    self.linear = spectral_norm(nn.Linear(in_features=256, out_features=1)) # real/fake logit output per image\n",
        "\n",
        "    self.embedding = spectral_norm(nn.Embedding(num_embeddings=10, embedding_dim=256)) # embedding for labels\n",
        "\n",
        "  def forward(self, x, labels):\n",
        "    features = self.model(x) # [N, 256, 4, 4]\n",
        "    features = self.pooling(features) # [N, 256, 1, 1]\n",
        "    features = torch.flatten(features, start_dim=1) # [N, 256] ; now we have f(x)\n",
        "\n",
        "    hfx = self.linear(features) # [N, 1] ; h(f(x)) -- the single score; the higher, the better\n",
        "    ey = self.embedding(labels) # [N, 256] ; e(y) -- converts each class label into learnable 256-dim vector\n",
        "\n",
        "    dot_product = torch.sum(features * ey, dim=1, keepdim=True) # computes dot product of f(x) - (N, 256) and e(y) - (N, 256)\n",
        "\n",
        "    logit = hfx + dot_product # [N, 1]\n",
        "\n",
        "    return logit\n",
        "\n",
        "    features = self.linear()\n",
        "    pass"
      ],
      "metadata": {
        "id": "AiRJTWoPsgMR"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rk20pijyyJ5W"
      },
      "execution_count": 17,
      "outputs": []
    }
  ]
}