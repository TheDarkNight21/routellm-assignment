{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN9rgQhdbLgSYmvHx57sjeo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheDarkNight21/routellm-assignment/blob/main/cgan_implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorboardX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "fKvy7968mGkd",
        "outputId": "31db1beb-5157-4c51-fd11-679796987f52"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorboardX\n",
            "  Downloading tensorboardx-2.6.4-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from tensorboardX) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorboardX) (25.0)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.12/dist-packages (from tensorboardX) (5.29.5)\n",
            "Downloading tensorboardx-2.6.4-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.6.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "pSZPu6KEE615"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.datasets import ImageFolder, CIFAR10\n",
        "from torchvision import transforms\n",
        "from torch import autograd\n",
        "from torch.autograd import Variable\n",
        "from torchvision.utils import make_grid\n",
        "from tensorboardX import SummaryWriter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "print('torch version:',torch.__version__)\n",
        "print('device:', device)"
      ],
      "metadata": {
        "id": "iFnTcJ_nE_Dp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dfcd07b-bcb8-45ed-d6f3-080d32b2d193"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch version: 2.8.0+cu126\n",
            "device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "pipeline of pre processing steps applied to each image"
      ],
      "metadata": {
        "id": "6UAh0ZKSpHba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(), # converts a PIL image/numpy array to torch.FloatTensor with shape (Channel, Height, Width)\n",
        "    transforms.Normalize([0.5], [0.5], [0.5]) # applies per channel normaliztion so values range from [-1, 1] instead of [0,1] -- good since we will be using tanh as final activation function\n",
        "    # need [0.5] 3 times since we have 3 channels (dataset is in RGB)\n",
        "    ])"
      ],
      "metadata": {
        "id": "_1wV3C8MpRNh"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "load data / parameters"
      ],
      "metadata": {
        "id": "Kc2Mo5Y8rYMn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_size = 32 # Image size\n",
        "batch_size = 64  # Batch size\n",
        "\n",
        "data_loader = torch.utils.data.DataLoader(CIFAR10('data', train=True, download=True, transform=transform), batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSQqfCYurBWw",
        "outputId": "526fce52-e23b-4cc1-b8af-58bcdd4939cc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:02<00:00, 75.8MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "discriminator"
      ],
      "metadata": {
        "id": "IKu4iM9osgqF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# nn.Module makes our lives easier; it is a base class that tracks all parameters and needs a forward() method for forward prop\n",
        "class conditionalDiscriminator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super.__init__()\n",
        "\n",
        "  def forward(self, x, labels):\n",
        "    pass"
      ],
      "metadata": {
        "id": "AiRJTWoPsgMR"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rk20pijyyJ5W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}